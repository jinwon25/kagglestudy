# 6주차 캐글 필사 리마인드 학습

## 1주차 – Titanic

### 배운 점
- **교차검증 & 튜닝**  
  - `StratifiedKFold`로 클래스 비율을 유지하며 모델 평가  
  - `GridSearchCV`로 최적 파라미터를 찾는 과정을 이해  

- **전처리 실습**  
  - 연관 변수를 이용해 결측치를 중위값으로 채우는 방법  
  - 이상치가 여러 개 모인 행을 찾아 제거하는 과정  
  - 가족 크기(`Fsize`)를 이용해 “혼자”, “작은 가족”, “중간 가족”, “큰 가족” 같은 파생변수 생성  

- **학습 곡선 & 해석**  
  - `learning_curve`로 과적합 여부를 시각적으로 파악  
  - 트리 모델의 `feature_importances_`로 중요한 변수 확인  

- **앙상블 개념**  
  - Bagging, Boosting, Stacking, Voting의 기본 아이디어  
  - Soft Voting으로 여러 모델의 예측 확률을 평균하는 방법  

### 보완할 점
- **더 다양한 모델 탐색**  
  - AdaBoost 외에도 RandomForest, XGBoost 같은 모델을 GridSearchCV나 RandomizedSearchCV로 튜닝해 보기  
  - Bayesian Optimization 등의 기법도 경험해 보기  

- **스태킹 구조 심화**  
  - Level 1 → Level 2 과정에서 데이터 누수가 없도록 구체적인 방법 확인  
  - 메타 모델에서 어떤 Base 모델을 더 중요하게 사용하는지 `feature_importances_`로 분석해 보기  

> **데이터 누수(Data Leakage):** 모델이 학습할 때, 평가 대상이 될 검증/테스트 데이터의 정보(정답이나 미래 데이터 등)를 미리 사용하여 학습해 버리는 문제

---

## 2주차 – Porto Seguro’s Safe Driver Prediction

### 배운 점
- **이진 인코딩(Binary Encoding)**  
  - 원-핫 인코딩보다 컬럼 수를 크게 줄일 수 있음 (≈ log₂(N))  
  - 트리 계열 모델(RF, LGBM, XGB 등)과 잘 어울리는 인코딩 방법  

- **OOF(Out-of-Fold) 예측**  
  - 훈련 데이터를 Fold별로 나눠서 “한 번도 본 적 없는 데이터”처럼 예측값을 얻는 방식  
  - 테스트 데이터는 각 Fold 예측값 평균으로 최종 예측 생성  

- **스태킹 구조**  
  - Base 모델(RF, XGB, LGBM 등) → 메타 모델(XGBoost, LightGBM) → 최종 앙상블  
  - 서로 다른 모델이 다양한 예측을 할수록 성능이 좋아짐  

- **평가지표 & 불균형 처리**  
  - `AUC`와 `Gini` 개념 이해(`Gini = 2*AUC − 1`)  
  - 불균형한 레이블에서 OOF 예측이 과적합을 줄여 줌  

### 보완할 점
- **Data Leakage 점검**  
  - 스태킹 과정에서 메타 모델이 훈련 데이터 전체 레이블을 미리 보는지 코드 레벨에서 완전히 확인  
  - Fold 분할 후 예측·병합 과정에서 누수가 발생하지 않도록 면밀히 체크  

- **파라미터 튜닝 심화**  
  - Level 1, Level 2, Level 3 모델을 각각 Grid/Random Search로 튜닝해 보기  
  - XGBoost/LGBM처럼 파라미터가 많은 모델의 탐색 범위를 효율적으로 설정하는 연습 필요  

- **메타 모델 해석**  
  - 메타 데이터(각 Base 모델 예측값)로 학습된 메타 모델이 어떤 예측을 더 중요하게 여기는지 `feature_importances_`로 살펴보기  
  - 스태킹 구조에서 Base 모델 간 기여도를 시각화해 보는 경험 필요  

---

## 3주차 – New York City Taxi Trip Duration

### 배운 점
- **거리 계산 & 로그 변환**  
  - 픽업/드롭오프 좌표 간 유클리디안 거리 계산  
  - 거리 값이 크면 분포가 한쪽으로 치우치므로 로그 변환으로 완화  

- **PCA(주성분 분석)**  
  - 80차원 클러스터 분포를 3차원(PC1, PC2, PC3)으로 줄여서 핵심 패턴 파악  
  - PC2, PC3가 각각 “야간 이동”과 “이른 아침 출근” 패턴을 보여 주는 것을 시각적으로 이해  

- **지리 시각화**  
  - Matplotlib으로 출발·도착 지점을 색으로 구분(마젠타, 초록)하고 화살표로 이동 흐름 표현  

### 보완할 점
- **실제 주행 경로/시간 반영**  
  - 유클리디안 거리는 교통 상황을 반영하지 않음  
  - OpenStreetMap이나 Google Directions API로 실제 도로 거리나 예상 소요 시간을 추가해 보기  

- **PCA 이후 활용**  
  - PCA 결과를 KMeans 같은 클러스터링에 사용해 보거나, 시계열 이상 탐지에 응용하는 실습 부족  
  - 이벤트(연휴, 축제 등)와 PC 값 변화를 연관 지어 분석해 보는 방법 필요  

- **시각화 기법 확장**  
  - Matplotlib 화살표 외에 Folium, Plotly로 **인터랙티브 지도** 만들기  
  - 3D PCA 결과를 Plotly 애니메이션으로 표현해 보는 경험 부족  

- **최종 예측 모델 구성**  
  - EDA와 PCA 위주에서 벗어나, 택시 트립 소요 시간을 예측하는 회귀 모델(랜덤포레스트, XGBoost 등) 구축·평가 과정이 누락됨  

---

## 4주차 – House Prices

### 배운 점
- **왜도 정규화 기법**  
  - 로그, 제곱근, 역수, Box-Cox 변환 등을 적용해 보고 어떤 상황에서 효과적인지 이해  
  - Box-Cox 변환으로 λ 값을 찾고 데이터를 정규 분포에 가깝게 만드는 원리 습득  

- **회귀 모델별 특징**  
  - Lasso (L1 규제), ElasticNet (L1+L2 규제), Kernel Ridge(커널 트릭) 각각의 장단점 파악  
  - 집값처럼 큰 값 차이가 중요한 문제에 `RMSLE` 평가 지표가 왜 적합한지 체감  

- **스태킹(메타 모델)**  
  - Base 모델(Lasso, ElasticNet, KRR 등) → 검증 데이터 예측값 모아 메타 모델(XGB, LGBM 등) 학습 → 최종 예측 구조 실습  

### 보완할 점
- **Box-Cox vs Yeo-Johnson 비교**  
  - Box-Cox는 x>0 데이터만, Yeo-Johnson은 음수도 가능하다는 차이를 실제 λ 추정 후 분포 비교해 보기  
  - `scipy.stats.boxcox`와 `sklearn.preprocessing.PowerTransformer` 사용법을 직접 실습  

- **회귀 모델 추가 실험**  
  - Lasso/ElasticNet/KRR 외에 Ridge, RandomForestRegressor, XGBoostRegressor, LightGBMRegressor 등을 비교하며  
    - 학습 속도, 메모리 사용량, 평가 점수(RMSLE, RMSE, MAE 등)를 확인해 보는 경험 필요  

- **메타 모델 과적합 방지**  
  - 메타 모델 학습 단계에서 다시 CV를 적용해 “완전히 새로운 데이터”처럼 예측값을 만드는 과정 상세히 실습  
  - 메타 모델이 과도하게 학습하지 않도록 early stopping이나 정규화 등 방법 적용해 보기  

- **회귀 결과 해석 & 시각화**  
  - 잔차 분석(Residual Plot, Q-Q Plot)으로 어떤 가격대에서 오차가 큰지 확인  
  - SHAP, LIME을 활용해 집값 예측에 가장 큰 영향을 미친 피처를 시각적으로 요약  

---

## 5주차 – PetFinder.my Adoption Prediction

### 배운 점
- **이미지 흐림 판정**  
  - OpenCV `Laplacian` 연산자로 이미지 경계(엣지) 정도를 계산해 분산이 낮으면 흐림, 높으면 선명으로 판단  

- **차원 축소: SVD vs NMF**  
  - SVD(LSA)로 희소 문서×단어 행렬을 잠재 의미 공간으로 압축하는 원리 이해  
  - NMF는 음수가 없는 분해 결과가 토픽 해석에 더 직관적임을 경험  

- **QWK(Quadratic Weighted Kappa)**  
  - 순위형 레이블(AdoptionSpeed 0~4) 예측 시 “얼마나 크게 틀렸나”를 반영하는 평가지표  
  - 단순 반올림 대신 **경계(threshold) 최적화**로 분류 성능을 높이는 아이디어 습득  

### 보완할 점
- **경계 최적화 기법 비교**  
  - 그리드 서치, 이진 탐색, Scipy 최적화 함수 중 어떤 방법을 선택했는지 구체적으로 살펴볼 필요  
  - “Threshold 변경 시 QWK 점수 변화”를 그래프로 시각화해 보기  

- **이미지 특징 추출 다변화**  
  - Laplacian 외에도 Sobel, Canny, HOG, ORB, SIFT 같은 기법을 비교 실습  
  - 이미지 크기, 대비, 노이즈가 Laplacian 분산 값에 미치는 영향을 실험해 보기  

- **SVD vs NMF 결과 해석 비교**  
  - 두 기법 적용 후 워드 클라우드나 토픽별 단어 분포 차이를 시각적으로 비교  
  - 데이터 크기, 계산 속도, 해석 편의성 등을 직접 실험해 보기


## 개인적으로 공부해볼 만한 Kaggle 데이터셋

### 1. Google Landmark Recognition (Landmark Retrieval)

- **링크**: https://www.kaggle.com/c/landmark-recognition-2021  
- **데이터 규모/특징**  
  - 수십만 장의 랜드마크 이미지(여러 해상도) + 레이블(랜드마크 ID)  
  - “수백만 개 이미지 중 동일 랜드마크 찾기”처럼 이미지 유사도 검색 문제  

=> **이미지 처리 최적화**

---

## 2. CommonLit Readability Prize

- **링크**: https://www.kaggle.com/c/commonlitreadabilityprize  
- **데이터 규모/특징**  
  - 영어 지문(수백 단어 단위) 약 10만 건 + readability score(독해 난이도, 실수로 도서관 피드백)  
  - “텍스트 → 실수형 점수(0~100점)” 회귀 문제로, 자연어 전처리와 회귀 모델 성능 최적화 과제  

=>  **텍스트 회귀 모델**

---

## 3. RSNA Pneumonia Detection Challenge

- **링크**: https://www.kaggle.com/c/rsna-pneumonia-detection-challenge  
- **데이터 규모/특징**  
  - 약 30,000장 이상의 흉부 X-ray DICOM 이미지 + 폐렴 여부 및 바운딩 박스(Bounding Box) 레이블  
  - “의료 영상에서 폐렴 병변을 객체 탐지(Object Detection)하는 과제”로, YOLO, Faster R-CNN, Mask R-CNN 등 적용 필요  

=> **의료 영상 객체 탐지**