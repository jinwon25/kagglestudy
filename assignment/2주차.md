# 2ì£¼ì°¨ Porto Seguroâ€™s Safe Driver Prediction ìºê¸€ í•„ì‚¬

## ì°¸ê³  ë…¸íŠ¸ë¶

[Porto Seguro Tutorial: end-to-end ensemble - Yifan Xie](https://www.kaggle.com/code/yifanxie/porto-seguro-tutorial-end-to-end-ensemble#4.-Level-2-ensemble)


## ë‚´ìš© ì •ë¦¬

### ìŠ¤íƒœí‚¹(Stacking)ì´ë€?

ìŠ¤íƒœí‚¹ì€ ì—¬ëŸ¬ ê°œì˜ ê°œë³„ ëª¨ë¸ë“¤ì„ í•™ìŠµì‹œí‚¨ í›„, ê·¸ë“¤ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì‚¼ì•„ **ë©”íƒ€ ëª¨ë¸**ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ë°©ë²•

- **ê°œë³„ ëª¨ë¸ë“¤:** ì„œë¡œ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ëŠ” ë‹¤ì–‘í•œ ëª¨ë¸
- **ë©”íƒ€ ëª¨ë¸:** ê°œë³„ ëª¨ë¸ë“¤ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ìµœì¢… ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸

![ìŠ¤í¬ë¦°ìƒ·](../image/screenshot4.png)

---
### ë³¸ ë…¸íŠ¸ë¶ì—ì„œì˜ ìŠ¤íƒœí‚¹ íë¦„

- **Level 1:** ë‹¤ì–‘í•œ ê°œë³„ ëª¨ë¸(Base Models)ë“¤ì˜ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± (OOF ë°©ì‹)
- **Level 2:** Level 1 ê²°ê³¼ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë˜ ë‹¤ë¥¸ ëª¨ë¸ì„ í•™ìŠµ (Meta-Model)
- **Level 3:** Level 2 ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì…ë ¥ìœ¼ë¡œ í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ

#### âœ… Level 1: Base Models & OOF ì˜ˆì¸¡ ìƒì„±

**ì£¼ìš” ëª¨ë¸**
- Random Forest
- Extra Trees
- Logistic Regression
- Bernoulli Naive Bayes
- XGBoost
- LightGBM

**í•µì‹¬: OOF(Out-of-Fold) ì˜ˆì¸¡**
- StratifiedKFoldë¡œ í›ˆë ¨ ë°ì´í„°ë¥¼ Kê°œë¡œ ë‚˜ëˆ”
- ê° ëª¨ë¸ì€ Kê°œì˜ í´ë“œë¡œ ë‚˜ëˆ  í•™ìŠµ ë° ê²€ì¦
- ê²€ì¦ì— ì‚¬ìš©ë˜ì§€ ì•Šì€ Foldë¡œ ì˜ˆì¸¡ê°’ì„ ìƒì„± â†’ train_pred
- í…ŒìŠ¤íŠ¸ì…‹ì€ ê° Foldì—ì„œ ì˜ˆì¸¡í•œ ê²°ê³¼ì˜ í‰ê·  â†’ test_pred
```PYTHON
rf_train_pred, rf_test_pred = cross_validate_sklearn(rf, x_train, y_train, x_test, kf)
```
=> ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ ê° ëª¨ë¸ë³„ë¡œ ì˜ˆì¸¡ê°’ì„ DataFrameìœ¼ë¡œ ì €ì¥

---
#### âœ… Level 2: ë©”íƒ€ ëª¨ë¸ í•™ìŠµ

**Level 1 ì˜ˆì¸¡ ê²°ê³¼ë“¤ì„ Featureë¡œ êµ¬ì„±**
```PYTHON
rf_train_pred, rf_test_pred = cross_validate_sklearn(rf, x_train, y_train, x_test, kf)
```

**Level 2 ë©”íƒ€ ëª¨ë¸**
- Cross-validationì„ í†µí•´ ë‹¤ì‹œ OOF ì˜ˆì¸¡ ìˆ˜í–‰
- ì´ ë•Œ AUC ê¸°ë°˜ ì˜ˆì¸¡ì´ê¸° ë•Œë¬¸ì— rankë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ë¨
```PYTHON
xgb_lv2_outcomes = cross_validate_xgb(xgb_params, lv1_train_df, y_train, lv1_test_df, kf, use_rank=True)
```
=> ì´ë ‡ê²Œ ì–»ì€ ê²°ê³¼ëŠ” ë ˆë²¨2 ì˜ˆì¸¡ê°’ì´ ë¨

---
#### âœ… Level 3: ìµœì¢… ìŠ¤íƒœí‚¹

**Level 2 ê²°ê³¼ë¥¼ ë‹¤ì‹œ featureë¡œ êµ¬ì„±**
```PYTHON
lv2_train = pd.DataFrame({
    'rf_lv2': rf_lv2_train_pred,
    'logit_lv2': logit_lv2_train_pred,
    'xgb_lv2': xgb_lv2_train_pred,
    'lgb_lv2': lgb_lv2_train_pred
})
```

**ìµœì¢… ëª¨ë¸ í•™ìŠµ (XGBoost & Logistic Regression)**
```PYTHON
xgb_lv3_outcomes = cross_validate_xgb(xgb_lv3_params, lv2_train, y_train, lv2_test, kf, use_rank=True)
logit_lv3_outcomes = cross_validate_sklearn(logit_lv3, lv2_train, y_train, lv2_test, kf, scale=True)
```

---
#### âœ… ìµœì¢… ì˜ˆì¸¡ ë° ì•™ìƒë¸”
- ë‘ ê°œì˜ Level 3 ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹¨ìˆœ í‰ê· ìœ¼ë¡œ ì•™ìƒë¸”
```PYTHON
submission['target'] = 0.5 * logit_lv3_test_pred + 0.5 * xgb_lv3_test_pred
```

---
#### ğŸ“Œ í•µì‹¬ ìš”ì•½

| ë‹¨ê³„      | ì£¼ìš” ëª¨ë¸                                | ëª©ì            | ì„ íƒ ì´ìœ  |
|-----------|-------------------------------------------|----------------|-----------|
| **Level 1** | RF, ET, Logit, NB, XGB, LGB               | ë‹¤ì–‘ì„± í™•ë³´    | ì„œë¡œ ë‹¤ë¥¸ íŒ¨í„´ì„ ê°€ì§„ ì˜ˆì¸¡ê°’ ìƒì„± |
| **Level 2** | XGB, LGB, RF, Logit                       | ì¡°í•© ìµœì í™”    | OOF ì˜ˆì¸¡ì„ ë©”íƒ€ ëª¨ë¸ì— ë„£ì–´ ì„±ëŠ¥ í–¥ìƒ |
| **Level 3** | XGB, Logit                                | ìµœì¢… ì¡°í•©      | ê°•ë ¥í•œ ëª¨ë¸ê³¼ ë‹¨ìˆœí•œ ëª¨ë¸ì„ í‰ê·  ì•™ìƒë¸” |
