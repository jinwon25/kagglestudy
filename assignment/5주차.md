# 5주차 PetFinder.my Adoption Prediction 캐글 필사

## 참고 노트북

[Models Combination - ALEXANDRALORENZO](https://colab.research.google.com/drive/1cjg0Rm4s47K1fEPXczTOz-3_M_Tf5fFC#scrollTo=iGDEEVHWXRvj)


## 내용 정리

### Laplacian 연산자

> “이미지의 경계(테두리)가 얼마나 뚜렷한지”를 수치로 보여주는 필터

- **원리**  
  픽셀 밝기의 “변화 속도”를 2차 미분으로 측정하여, 경계가 급격한 곳을 강조.
  - 1차 미분(경사도)은 **얼마나 빠르게 밝기가 변하나**를 보고, 2차 미분(Laplacian)은 **그 변하는 속도가 얼마나 급격히 바뀌는가**를 봄

- **흐림 판정**  
  1. `lap = cv2.Laplacian(gray, cv2.CV_64F)`  
  2. `blur_score = lap.var()`  
     - **높으면** → 선명한 이미지  
     - **낮으면** → 흐린 이미지

=> 선명한 사진은 경계가 또렷해서 **Laplacian 결과값이 크게 요동**치고, 흐린 사진은 경계가 뭉개져서 **결과값이 잔잔히 작게 변함**

---
### SVD & NMF 

#### SVD (Latent Semantic Analysis)
- **무엇을 하나?**  
  많은 문장에서 같이 나오는 단어들을 묶어서, 긴 문장을 “몇 개 숫자”로 줄여 주는 방법  
- **어떻게?**  
  1. 문장×단어 표를 만든 뒤  
  2. 수학적으로 “5차원” 같은 작은 공간으로 꾹 눌러 압축  
  3. 압축된 숫자 벡터끼리 거리 보면, 뜻이 비슷한 문장은 가깝게 놓임  
- **왜 좋냐?**  
  - 문장 하나를 5개의 숫자로 표현 → 컴퓨터가 빨리 처리  
  - 드물게 쓰이는 단어 노이즈가 쏙 빠짐

#### NMF (Non-negative Matrix Factorization)
- **무엇을 하나?**  
  각 문장이 “어떤 주제(토픽)”를 얼마나 담았는지, 점수로 알려 주는 방법  
- **어떻게?**  
  1. 문장×단어 표를  
  2. “주제별 단어 분포”와 “문장별 주제 점수” 두 표로 나눠 학습  
  3. 결과로 문장은 `[0.2, 0.5, 0.1, …]` 같은 주제별 점수 벡터가 됨  
- **왜 좋냐?**  
  - 어떤 문장이 “귀여움”에 0.8, “건강”에 0.1 들어 있는 식으로 직관적  
  - 음수가 없어서 해석이 더 단순

<br>

=> **SVD:** 각 잠재 의미축에 대해 “어떤 단어들이 얼마나 중요한지(가중치)”를 보여줌<br>
=> **NMF:** 각 토픽에 대해 “어떤 단어들이 주제를 이루는지”와, 각 문서가 “토픽을 얼마나 포함하는지”를 보여줌

---
### Quadratic Weighted Kappa (QWK)

#### 무엇을 측정하나?
- 두 평가자(여기서는 “실제 AdoptionSpeed” vs. “모델 예측 AdoptionSpeed”) 간 **일치도**를 측정함

#### 왜 “Quadratic Weighted”인가?
- 단순 맞/틀이 아니라 “얼마나 크게 틀렸는가”를 반영  
  - 예: 실제 0(당일 입양)을 모델이 4(100일 이상 미입양)로 예측하면, 0↔4 오차는 0↔1 오차보다 훨씬 더 큰 패널티를 줘야 함  
- 거리가 멀수록 패널티를 제곱(quadratic) 형태로 키움

#### 값의 범위
- **+1.0** → 완전 일치  
- **0.0** → 우연히 맞춘 수준 (평가자 간 상관 없음)  
- **–1.0** → 완전 반대 평가  

---
### 경계 최적화 (Optimized Boundaries)

#### 문제의 시작점
LightGBM은 기본적으로 **회귀 모델**이기 때문에,  
정수 레이블(0,1,2,3,4)을 예측하려 해도 실제로는 실수값(예: 1.37, 2.89)을 뱉어냄   
이 실수를 단순 반올림하면 최적이 아닐 수 있음

```python
# 예시: 모델이 내놓는 연속값
y_pred = [0.3, 1.9, 2.2, 3.8, 4.1, …]

# 나이브한 반올림
# → [0, 2, 2, 4, 4, …]
```